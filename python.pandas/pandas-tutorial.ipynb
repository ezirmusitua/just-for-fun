{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas Tutorial From Kaggle  \n",
    "[Kaggle Learn: Pandas](https://www.kaggle.com/learn/pandas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: \n",
      " (4, 2)\n",
      "head 1: \n",
      "    Age      Name\n",
      "0   22  jferroal\n",
      "sample 2: \n",
      "    Age         Name\n",
      "0   22     jferroal\n",
      "2   22  autisumrize\n",
      "                     Bob           Sue\n",
      "Product A    I liked it.  Pretty good.\n",
      "Product B  It was awful.        Bland.\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "# create data frame\n",
    "persons = pd.DataFrame({\n",
    "    'Name': ['jferroal', 'ezirmusitua', 'autisumrize', 'jeff'],\n",
    "    'Age': [22, 22, 22, 22]\n",
    "})\n",
    "print('shape: \\n', persons.shape)\n",
    "print('head 1: \\n', persons.head(1))\n",
    "print('sample 2: \\n', persons.sample(2))\n",
    "persons = pd.DataFrame({'Bob': ['I liked it.', 'It was awful.'], \n",
    "                        'Sue': ['Pretty good.', 'Bland.']},\n",
    "                       index=['Product A', 'Product B'])\n",
    "print(persons)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pd.DataFrame    \n",
    "`pd.DataFrame(dict, index=list of rowlabel)`  \n",
    "用法：传入 key(row label)-val(entries) dict  \n",
    "可选参数: index=list of row label  \n",
    "> 如果没有指定 index，默认 row label 为 range(0, row_count)  \n",
    "> 如果指定 index 数量和 row count 不符，index 数量决定  \n",
    "\n",
    "`pd.DataFrame.head(count)`  \n",
    "显示头 count 行数据  \n",
    "\n",
    "`pd.DataFrame.shape`  \n",
    "显示 DataFrame 的 (row, column) 数据  \n",
    "\n",
    "`pd.DataFrame.sample(count)`  \n",
    "显示 DataFrame 中随机 count 行  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1\n",
      "1    2\n",
      "2    3\n",
      "3    4\n",
      "4    5\n",
      "dtype: int64\n",
      "2015 Sales    30\n",
      "2016 Sales    35\n",
      "2017 Sales    40\n",
      "Name: Product A, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "series = pd.Series([1, 2, 3, 4, 5])\n",
    "print(series)\n",
    "series = pd.Series([30, 35, 40], index=['2015 Sales', '2016 Sales', '2017 Sales'], name='Product A')\n",
    "print(series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pd.Series   \n",
    "用法：传入一个 list   \n",
    "可选参数：index（类似 DataFrame 的作用），name - 指定 Series 的名称  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Name  Age\n",
      "id               \n",
      "0   jferroal   22\n",
      "       Name  Age  id\n",
      "0  jferroal   22   0\n"
     ]
    }
   ],
   "source": [
    "csv_demo = pd.read_csv('./demo.csv', index_col=2)  \n",
    "print(csv_demo)\n",
    "csv_demo = pd.read_csv('./demo.csv')  \n",
    "print(csv_demo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pd.read_csv  \n",
    "从 csv 文件中读取数据并转变为 DataFrame  \n",
    "可以使用参数 index_col=col_index 指定哪一列为 index 指示，不指定时默认生成  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ID   NAME  AGE     ADDRESS   SALARY\n",
      "0   1   Paul   32  California  20000.0\n",
      "1   2  Allen   25       Texas  15000.0\n",
      "2   3  Teddy   23      Norway  20000.0\n",
      "3   4   Mark   25  Rich-Mond   65000.0\n"
     ]
    }
   ],
   "source": [
    "def prepare_demo_table(conn):\n",
    "    c = conn.cursor()\n",
    "    c.execute('''CREATE TABLE COMPANY\n",
    "       (ID INT PRIMARY KEY     NOT NULL,\n",
    "       NAME           TEXT    NOT NULL,\n",
    "       AGE            INT     NOT NULL,\n",
    "       ADDRESS        CHAR(50),\n",
    "       SALARY         REAL);''')\n",
    "\n",
    "    c.execute(\"INSERT INTO COMPANY (ID,NAME,AGE,ADDRESS,SALARY) \\\n",
    "      VALUES (1, 'Paul', 32, 'California', 20000.00 )\")\n",
    "\n",
    "    c.execute(\"INSERT INTO COMPANY (ID,NAME,AGE,ADDRESS,SALARY) \\\n",
    "      VALUES (2, 'Allen', 25, 'Texas', 15000.00 )\")\n",
    "\n",
    "    c.execute(\"INSERT INTO COMPANY (ID,NAME,AGE,ADDRESS,SALARY) \\\n",
    "      VALUES (3, 'Teddy', 23, 'Norway', 20000.00 )\")\n",
    "\n",
    "    c.execute(\"INSERT INTO COMPANY (ID,NAME,AGE,ADDRESS,SALARY) \\\n",
    "      VALUES (4, 'Mark', 25, 'Rich-Mond ', 65000.00 )\")\n",
    "\n",
    "    conn.commit()\n",
    "conn = sqlite3.connect('./demo.sqlite')\n",
    "# prepare_demo_table(conn)\n",
    "sqlite3_demo = pd.read_sql_query(\"SELECT * FROM COMPANY\", conn)\n",
    "print(sqlite3_demo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pd.read_sql_query  \n",
    "利用 sql connection 执行 select 语句从而获取数据库中的数据  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    部门   姓名    具体任职  总分 等级  工作业绩分  任职浮动分   备注\n",
      "1  NaN  丁俊波  学生会副主席  66  B    1.0    NaN  NaN\n",
      "3  NaN  金晓永  学生会副主席  66  B    1.0    NaN  NaN\n"
     ]
    }
   ],
   "source": [
    "excel_demo = pd.read_excel('./demo.xls')\n",
    "print(excel_demo.iloc[1:5:2,])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pd.read_excel  \n",
    "从 excel 文件中读取数据并转化为 DataFrame  \n",
    "可以通过指定 `sheet_name=?` 指定读取 excel 中的那个 sheet  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Table 'COMPANY_NEW' already exists.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-8b8cef520e00>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0msqlite3_demo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./demo.out.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0msqlite3_demo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_excel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./demo.out.xls'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0msqlite3_demo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_sql\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'COMPANY_NEW'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\jferroal\\.venvs\\ds\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mto_sql\u001b[1;34m(self, name, con, flavor, schema, if_exists, index, index_label, chunksize, dtype)\u001b[0m\n\u001b[0;32m   1532\u001b[0m         sql.to_sql(self, name, con, flavor=flavor, schema=schema,\n\u001b[0;32m   1533\u001b[0m                    \u001b[0mif_exists\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mif_exists\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex_label\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindex_label\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1534\u001b[1;33m                    chunksize=chunksize, dtype=dtype)\n\u001b[0m\u001b[0;32m   1535\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1536\u001b[0m     def to_pickle(self, path, compression='infer',\n",
      "\u001b[1;32mc:\\users\\jferroal\\.venvs\\ds\\lib\\site-packages\\pandas\\io\\sql.py\u001b[0m in \u001b[0;36mto_sql\u001b[1;34m(frame, name, con, flavor, schema, if_exists, index, index_label, chunksize, dtype)\u001b[0m\n\u001b[0;32m    471\u001b[0m     pandas_sql.to_sql(frame, name, if_exists=if_exists, index=index,\n\u001b[0;32m    472\u001b[0m                       \u001b[0mindex_label\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindex_label\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mschema\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 473\u001b[1;33m                       chunksize=chunksize, dtype=dtype)\n\u001b[0m\u001b[0;32m    474\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    475\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jferroal\\.venvs\\ds\\lib\\site-packages\\pandas\\io\\sql.py\u001b[0m in \u001b[0;36mto_sql\u001b[1;34m(self, frame, name, if_exists, index, index_label, schema, chunksize, dtype)\u001b[0m\n\u001b[0;32m   1509\u001b[0m                             \u001b[0mif_exists\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mif_exists\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex_label\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindex_label\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1510\u001b[0m                             dtype=dtype)\n\u001b[1;32m-> 1511\u001b[1;33m         \u001b[0mtable\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1512\u001b[0m         \u001b[0mtable\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunksize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1513\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jferroal\\.venvs\\ds\\lib\\site-packages\\pandas\\io\\sql.py\u001b[0m in \u001b[0;36mcreate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    590\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    591\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mif_exists\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'fail'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 592\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Table '%s' already exists.\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    593\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mif_exists\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'replace'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    594\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpd_sql\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop_table\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mschema\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Table 'COMPANY_NEW' already exists."
     ]
    }
   ],
   "source": [
    "sqlite3_demo.sample(2).to_csv('./demo.out.csv')\n",
    "sqlite3_demo.sample(2).to_excel('./demo.out.xls')\n",
    "sqlite3_demo.sample(2).to_sql('COMPANY_NEW', conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### write DataFrame to file/sql  \n",
    "DataFrame 对象有 to_* 方法可以将数据写入到不同的地方  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index  \n",
    "1. 类似 python dict 的操作方式，但是可以使用 . 操作符  \n",
    "2. loc & iloc(both are row first, column second)    \n",
    "    > pandas index 的操作范式：基于 index(iloc) 和 基于 label(loc)  \n",
    "\n",
    "### iloc  \n",
    "**the first element of the range is included and the last one excluded**  \n",
    "```python  \n",
    "# get all row with column 0(exclude index)  \n",
    "df.iloc[from_row:to_row:step, from_col:to_col:step]\n",
    "```  \n",
    "### loc  \n",
    "loc can index any stdlib type: strings\n",
    "**the first and the last element of the range is included**    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Using iloc: \\n')\n",
    "print(excel_demo.iloc[:100:5, 2:6:2])\n",
    "print('Using loc: \\n')\n",
    "print(excel_demo.loc[:101:5, '具体任职':'工作业绩分':2])\n",
    "_tmp = pd.DataFrame.copy(excel_demo)\n",
    "_tmp.set_index('姓名')\n",
    "print(_tmp.loc['顾迪文':'戴鑫雷', :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manipulating the index  \n",
    "`set_index` - set specific column as DataFrame's index  \n",
    "### Conditional selection  \n",
    "```python  \n",
    "# df.loc[condition]  \n",
    "df.loc[df.col1 == <val1>]  \n",
    "df.loc[(df.col1 == <val1>) & (df.col2 == <val2>)]\n",
    "df.loc[(df.col1 == <val1>) | (df.col2 == <val2>)]\n",
    "df.loc[df.col1.isin([<val1>, <val2>])]  \n",
    "df.loc[df.col1.notnull()]  \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(excel_demo.loc[excel_demo['等级'].isin(['A', 'B'])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assigning data  \n",
    "```python  \n",
    "# assign all col value as everyone  \n",
    "df['col'] = 'everyone'  \n",
    "# assign col value from len(reviews) to 1)\n",
    "df['col'] = range(len(reviews), 0, -1)\n",
    "```  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_demo['任职浮动分'] = '0'\n",
    "print(excel_demo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary functions  \n",
    "### describe  \n",
    "** only work with int value **  \n",
    "`(DataFrame/Series).describe` - generates a high-level summary of the attributes of the given column  \n",
    "### mean  \n",
    "** only work with int value **  \n",
    "`(DataFrame/Series).mean` - mean of the points allotted  \n",
    "### unique  \n",
    "`Series.unique` - see a list of unique values   \n",
    "### value_counts  \n",
    "`Series.value_counts` - see a list of unique values and how often they occur in the dataset  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# excel_demo.describe()\n",
    "# excel_demo.mean()\n",
    "# excel_demo.median()\n",
    "# excel_demo.min()\n",
    "# excel_demo.max()\n",
    "# excel_demo.std()\n",
    "# excel_demo['具体任职'].unique()\n",
    "# excel_demo.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maps  \n",
    "a function that takes one set of values and \"maps\" them to another set of values  \n",
    "**The difference between map & apply**  \n",
    "1. map takes a Series as input, apply takes a DataFrame/Series as input    \n",
    "\n",
    "Some common built in map function: operator(+, -, *, / ...) for basic type    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# excel_demo['工作业绩分'].map(lambda x: x * 10)\n",
    "# excel_demo['工作业绩分'].apply(lambda x: x * 10)\n",
    "# excel_demo.apply(lambda x: print(x))\n",
    "# excel_demo\n",
    "# tmp = excel_demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouping  \n",
    "\n",
    "### groupby\n",
    "grouping returns data in index order, not in value order\n",
    "`pd.DataFrame.groupby`  \n",
    "```python  \n",
    "df = pd.read_csv('./demo.csv')\n",
    "\n",
    "gbdf = df.groupby('col1')\n",
    "# this will return count of each value of col1\n",
    "gbdf.col1.counts()  \n",
    "# this will return minimum price of each col1 group\n",
    "gbdf.price.min()\n",
    "# ...\n",
    "```  \n",
    "groupby 根据 特定的 column 将 DataFrame 中的数据聚合到一起  \n",
    "> You can think of each group we generate as being a slice of our DataFrame containing only data with values that match. This DataFrame is accessible to us directly using the apply method, and we can then manipulate the data in any way we see fit  \n",
    "\n",
    "you can also group by more than one column.\n",
    "```python  \n",
    "#  pick out the best wine by country and province\n",
    "reviews.groupby(['country', 'province']).apply(lambda df: df.loc[df.points.argmax()])\n",
    "```  \n",
    "\n",
    "### agg  \n",
    "Run a bunch of different functions on DataFrame simultaneously\n",
    "\n",
    "### Multi-indexes  \n",
    "**A multi-index differs from a regular index in that it has multiple levels. For example**  \n",
    "```python  \n",
    "countries_reviewed = reviews.groupby(['country', 'province']).description.agg([len])\n",
    "mi = _.index\n",
    "type(mi)  \n",
    "```  \n",
    "in general the MultiIndex method you will use most often is the one for converting back to a regular index, the reset_index method: `countries_reviewed.reset_index()`  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sorting  \n",
    "### sort by values  \n",
    "`pd.DataFrame.sort_values(by='colname' or ['colname1', ...], ascending=True(default)/False)`    \n",
    "### sort by index  \n",
    "`pd.DataFrame.sort_index(by='colname' or ['colname1', ...], ascending=True(default)/False)`    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rename - 非原地操作  \n",
    "### rename columns  \n",
    "`df.rename(columns={'col1': 'ncol1'})`  \n",
    "### rename rows  \n",
    "`df.rename(index={0: 'firstEntry', 1: 'secondEntry'})`  \n",
    "### rename axises(坐标轴)  \n",
    "`df.rename_axis(\"rows_name\", axis='rows').rename_axis(\"columns_name\", axis='columns')`  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine  \n",
    "### concat  \n",
    "**just like list.concat**  \n",
    "**useful when we have data in different DataFrame or Series objects but having the same fields (columns)**  \n",
    "```python  \n",
    "dfc = pd.concat([df1, df2])  \n",
    "```\n",
    "### join  \n",
    "**like join action in SQL**  \n",
    "**combine different DataFrame objects which have an index in common**  \n",
    "```python\n",
    "left = canadian_youtube.set_index(['title', 'trending_date'])\n",
    "right = british_youtube.set_index(['title', 'trending_date'])\n",
    "left.join(right, lsuffix='_CAN', rsuffix='_UK')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method Chaining\n",
    "### What is Method Chaining  \n",
    "Method chaining is a methodology for performing operations on a DataFrame or Series that emphasizes continuity, like following:  \n",
    "```python  \n",
    "(ramen['Stars']\n",
    "     .replace('Unrated', None)\n",
    "     .dropna()\n",
    "     .astype('float64')\n",
    "     .head())\n",
    "```  \n",
    "\n",
    "### Why Method Chaining  \n",
    "1. it lessens the need for creating and mentally tracking temporary variables  \n",
    "2. emphasizes a correctly structured interative approach to working with data, where each operation is a \"next step\" after the last  \n",
    "3. easy to debug, comment out operations that don't work until you get to one that does, and then start stepping forward again  \n",
    "\n",
    "### Assign  \n",
    "assign method lets you create new columns or modify old ones inside of a DataFrame inline  \n",
    "```python\n",
    "wine.assign(\n",
    "    region_1=wine.apply(lambda srs: srs.region_1 if pd.notnull(srs.region_1) else srs.province, \n",
    "                        axis='columns')\n",
    ")\n",
    "# do the same thing  \n",
    "wine['region_1'] = wine['region_1'].apply(\n",
    "    lambda srs: srs.region_1 if pd.notnull(srs.region_1) else srs.province, \n",
    "    axis='columns'\n",
    ")\n",
    "```  \n",
    "### Pipe  \n",
    "perform an operation on the entire DataFrame at once, and replaces the current DataFrame which the output of your pipe  \n",
    "```python  \n",
    "def name_index(df):\n",
    "    df.index.name = 'review_id'\n",
    "    return df\n",
    "\n",
    "wine.pipe(name_index)\n",
    "```  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
